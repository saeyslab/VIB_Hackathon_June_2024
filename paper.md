---
title: "VIB Hackathon on spatial omics tools and methods"
title_short: "VIB Hackathon on spatial omics"
tags:
  - spatial omics
  - spatial transcriptomics
  - spatial proteomics
  - cell-cell communication
  - bioinformatics pipelines
authors:
  - name: Benjamin Rombaut
    orcid: 0000-0002-4022-715X
    affiliation: 1,2,3
  - name: Lotte Pollaris
    orcid: 0000-0002-0262-0540
    affiliation: 1,2,3
  - name: Chananchida Sang-aram
    affiliation: 1,2,3
  - name: Michiel Ver Cruysse
    affiliation: 1,3
  - name: Robrecht Cannoodt
    orcid: 0000-0003-3641-729X
    affiliation: 5,1,2
  - name: Frank Vernaillen
    affiliation: 4
  - name: Arne Defauw
    affiliation: 4
  - name: Julien Mortier
    affiliation: 4
  # ON-SITE HACKATHON PARTICIPANTS, FEEL FREE TO INSERT NAME HERE IN ALPHABETICAL ORDER
  # START
  - name: Mayar Ali
    orcid: 000-0002-0398-5699
    affiliation: 18,19
  - name: Kresimir Bestak
    orcid: 0009-0009-8245-9846
    affiliation: 6
  - name: Quentin Blampey
    orcid: 0000-0002-3836-2889
    affiliation: 16
  - name: Michele Bortolomeazzi
    orcid: 0000-0001-5805-5774
    affiliation: 10
  - name: Paula V M Cauhy
    orcid: 0000-0003-1004-3656
    affiliation: 26
  - name: Miray Cetin
    orcid: 0009-0001-7711-0211
    affiliation: 14
  - name: Daniel Dimitrov
    orcid: 0000-0002-5197-2112
    affiliation: 6
  - name: Francesca Drummer
    orcid:
    affiliation: 18, 20
  - name: Lorenzo Giordani
    orcid: 0000-0002-3417-2965
    affiliation: 24
  - name: Aroj Hada
    orcid: 0000-0002-0691-1214
    affiliation: 6,7
  - name: Luuk Harbers
    orcid: 0000-0003-3910-6497
    affiliation: 8
  - name: Miguel A. Ibarra-Arellano
    orcid: 0000-0001-8411-4854
    affiliation: 6
  - name: Paul Kiessling
    orcid: 0000-0002-9794-9532
    affiliation: 11
  - name: Laurens Lehner
    orcid: 0000-0001-7690-7168
    affiliation: 18
  - name: Susmita Mandal
    orcid: 0000-0003-2248-7860
    affiliation: 23
  - name: Benedetta Manzato
    orcid: 0009-0008-8369-2327
    affiliation: 21
  - name: Luca Marconato
    orcid: 0000-0003-3198-1326
    affiliation: 13
  - name: Claudio Novella-Rausell
    orcid: 0000-0002-7383-6090
    affiliation: 21
  - name: Anastasiia Okhtienko
    orcid: 0009-0003-5886-811X
    affiliation: 17
  - name: Giovanni Palla
    orcid: 0000-0002-8004-4462
    affiliation: 18
  - name: Daryna Pikulska
    orcid: 0009-0005-1638-0268
    affiliation: 11
  - name: Carlos Ariel Pulido-Vicuna
    orcid: 0000-0001-5049-6997
    affiliation: 22,8
  - name: Guillaume Sacchetti
    orcid: 0000-0002-8779-352X
    affiliation: 22,8
  - name: Alexander Sudy
    orcid: 0000-0002-7338-4119
    affiliation: 12
  - name: Lotte Van de Vreken
    orcid: 0009-0000-9283-4720
    affiliation: 15
  - name: Wouter-Michiel Vierdag
    orcid: 0000-0003-1666-5421
    affiliation: 13
  - name: Vladislav Vlasov
    orcid: 0009-0005-9514-4860
    affiliation: 9
  - name: Sai Nirmayi Yasa
    orcid: 0009-0003-6319-9803
    affiliation: 5
  - name: Estella Yixing Dong
    orcid: 0009-0003-5115-5686
    affiliation: 25
  # END
  - name: Ruth Seurinck
    orcid: 0000-0002-6636-7572
    affiliation: 1,2,3
  - name: Yvan Saeys
    orcid: 0000-0002-0415-1506
    affiliation: 1,2,3
affiliations:
  - name: Data Mining and Modelling for Biomedicine, VIB-UGent Center for Inflammation Research, Ghent, Belgium
    index: 1
  - name: Department of Applied Mathematics, Computer Science and Statistics, Ghent University, Ghent, Belgium
    index: 2
  - name: VIB Center for AI and Computational Biology, Ghent, Belgium
    index: 3
  - name: VIB Spatial Catalyst
    index: 4
  - name: Data Intuitive, Lebbeke, Belgium
    index: 5
  - name: Institute for Computational Biomedicine, Faculty of Medicine, Heidelberg University Hospital, Heidelberg, Germany
    index: 6
  - name: AI-Health Innovation Cluster, Heidelberg, Germany
    index: 7
  - name: VIB-KU Leuven Center for Cancer Biology, Leuven, Belgium
    index: 8
  - name: Brain and Systems Immunology Lab, Brussels Center for Immunology, Vrije Universiteit Brussel
    index: 9
  - name: ScOpen Lab, German Cancer Research Center (DKFZ), Heidelberg, Germany
    index: 10
  - name: RWTH Aachen, University Hospital
    index: 11
  - name: Center of Digital Health, Berlin Institute of Health at Charité – Universitätsmedizin Berlin, Germany
    index: 12
  - name: European Molecular Biology Laboratorium, Heidelberg, Germany
    index: 13
  - name: Systems Immunology and Single-Cell Biology, German Cancer Research Center (DKFZ), Heidelberg, Germany
    index: 14
  - name: VIB-UGent Center for Plant Systems Biology, Ghent, Belgium
    index: 15
  - name: MICS Laboratory, CentraleSupélec, Paris-Saclay University, Paris, France
    index: 16
  - name: Institute of Virology, Technical University of Munich, Munich, Germany
    index: 17
  - name: Institute of Computational Biology, Helmholtz Munich, Neuherberg, Germany
    index: 18
  - name: Institute for Tissue Engineering and Regenerative Medicine, Helmholtz Munich, Neuherberg, Germany
    index: 19
  - name: Institute for Stroke and Dementia Research, Klinikum Der Universität München, Ludwig-Maximilians-Universität, Munich, Germany
    index: 20
  - name: Department of Human Genetics, Leiden University Medical Center, Leiden 2333ZC, The Netherlands
    index: 21
  - name: Laboratory for Molecular Cancer Biology, Center for Cancer Biology, VIB, Leuven, Belgium; Department of Oncology, KU Leuven, Leuven, Belgium.
    index: 22
  - name: Institute of Pathology at Charité – Universitätsmedizin Berlin, Germany
    index: 23
  - name: Sorbonne Université, INSERM UMRS 974, Association Institut de Myologie, Centre de Recherche en Myologie, 75013 Paris, France.
    index: 24
  - name: Biomedical Data Science Center, Lausanne University Hospital; University of Lausanne, Lausanne, Switzerland.
    index: 25
  - name: UK Dementia Research Institute, University College London, WC1E 6BT, London, UK
    index: 26
  # ADD AFFILIATION HERE

date: 12 June 2024
cito-bibliography: paper.bib
event: VIBHackathonJune2024
biohackathon_name: "VIB Hackathon on spatial omics"
biohackathon_url: "https://hackmd.io/@berombau/BJetSxw8T"
biohackathon_location: "Ghent, Belgium, 2024"
group: Code repository
# URL to project git repo --- should contain the actual paper.md:
git_url: https://github.com/saeyslab/VIB_Hackathon_June_2024
# This is the short authors description that is used at the
# bottom of the generated paper (typically the first two authors):
authors_short: VIB Hackathon participants
---

<!-- Note that you can use https://sparontologies.github.io/cito/current/cito.html#objectproperties
for more detailed citations for text mining e.g. [@uses_method_in:marconato_spatialdata_2024] -->

<!-- This HackMD note is used for collaborative writing and will be copied to https://github.com/saeyslab/VIB_Hackathon_June_2024 at the end of the hackathon -->

# Introduction

During a three-day hackathon, work was performed on various topics within the field of spatial omics data analysis. The topics were organized in five workgroups and included benchmarking, pipelines, spatial transcriptomics, spatial proteomics, spatial multi-omics and cell-cell communication. Most tools and methods were considered in the context of the Python ecosystem for spatial [@marconato_spatialdata_2024] and single-cell [@virshup_scverse_2023] data analysis.

# Results

Results were summarized in a [final slide deck](https://docs.google.com/presentation/d/1HDf1PmQRNGcgCJZ3daF7dpjZK0miKqZFQM4KgrhzulY/edit?usp=sharing). A [project board](https://github.com/orgs/saeyslab/projects/5) collected all task items and GitHub Issues. Here we give a brief overview for each of the five workgroups.

## Workgroup pipelines

### Nextflow

During this hackathon, we have worked on and finished the template update for [nf-core/molkart](https://github.com/nf-core/molkart/pull/71), an nf-core pipeline for processing Molecular Cartography data, allowing for the next expansion that will include spot-based segmentation options. Additionally, we have added Spotiflow, a spot-detection tool into the nf-core framework.

### Isoquant

Isoquant is a tool for the reconstruction and quantification of single-cell long-read RNA data (e.g. from PacBio and Oxford Nanopore). Currently, Isoquant is not optimized for spatial data and is limited to reconstructing and quantifying transcripts from a few thousand barcodes at most. While this is often sufficient for single-cell long-read RNA data, spatial data can scale to many more barcodes.

We identified the current bottlenecks in Isoquant and started on implementing a fix to circumvent this. From initial testing we can now perform reconstruction and quantification of transcripts on millions of barcodes efficiently. Currently we are performing further testing to ensure that results and downstream analyses are unaffected before submitting the fix as a pull request.

### Infrastructure for pipelines

We merged support for incremental IO (partial read/write) in SpatialData [(PR)](https://github.com/scverse/spatialdata/pull/501). Identified an issue for [multiscale images](https://github.com/scverse/spatialdata/issues/577). Discussed support for apply function on raster data in SpatialData [(draft PR)](https://github.com/scverse/spatialdata/pull/407).

- Specific issues:
  - improve performance of isoquant for large spatial omics datasets
  - Build a computational benchmark for spatial omics data
    - identify datasets
    - identify first benchmarks
- Accessing remote datasets:
  - Upload spatial omics datasets to S3
  - Support for private remove object storage in SpatialData

## Workgroup spatial transcriptomics

### Napari plugin

Napari is a scalable interactive viewer for multi-dimensional data. It works natively in python. Within this hackathon, we worked on adding functionality to napari-spatialdata, a SpatialData plugin for napari. Firstly, we worked on reusing colors previously defined in the SpatialData object. Secondly, progress had been made to only visualize subsets of the cells. This would allow to plot a certain cell type colored by gene expression of gene x and another cell type colored by gene expression.  
Thirdly, work on the annotation widget has been performed and checked.
Lastly, it has been made possible for widgets to communicate with one another. An example screenshot of the annotation widget is [available](https://github.com/saeyslab/VIB_Hackathon_June_2024/tree/main/imgs/napari_annotation.png).

### Annotation workflows

We discussed user stories for a workflow that entails drawing annotations interactively with Napari and using the annotations in downstream analysis steps. To this end, we identified the following tasks that would enable such workflow:

- napari-spatialdata widget that would enable:
  1. Drawing annotations on a specific image or coordinate system.
  2. Rename the annotations, specifying various metadata to the annotation, such as the identity of the annotator, labels for the annotations and others.
  3. Save the annotations back to the spatialdata object and on-disk.
- Masked spatial graphs based on annotations: the annotations define specific areas of interest of the tissue. The analyst may wish to analyze the spatial structure enclosed in the annotations, or using the annotation as a "negative mask" in order to remove graph edges going across void regions of the tissue.
- Calculating and plotting gene expression trends at increasing distance to the annotation of interest (or within the boundaries of the annotations of interest). This is similar to the squidpy function `sq.tl.var_by_distance` but computing distances to polygon boundaries and not simply to the centroid of the polygon.

### Visium HD on-the-fly rasterization

As mentioned in [this SpatialData issue](https://github.com/scverse/spatialdata/issues/572), Visium HD bins can't be rasterized in memory (i.e., converted to an image) as a single full-genome image. Indeed, the smallest bins are 2-microns-width squares with full-genome sequencing. Still, for visualization and analyses purposes, rasterization is needed. Therefore, we opened a new [PR for bins rasterization](https://github.com/scverse/spatialdata/pull/578), on which we support two modes:

- rasterization of one or multiple channels (in-memory). It uses the indices of the sparse table in CSC format for efficiency.
- lazy rasterization of the full data with Dask (in particular, using map_blocks). The data is therefore rasterized when needed, for instance to display one or a few channels in napari-spatialdata.

Remaining steps includes (i) adding tests and (ii) adding some notebook examples.

### Visium HD and Xenium

Recently a [dataset](https://www.10xgenomics.com/products/visium-hd-spatial-gene-expression/dataset-human-crc) was published [@oliveira_characterization_2024] that applied multimodal spatial transcriptomics techniques on the same colorectal cancer samples on consecutive sections. Namely, Visium HD, Xenium as well as Visium v2 and scRNAseq was performed. Our goal was to compare the high resolution sequencing-based data from Visium HD with the imaging-based Xenium to show whether they can be used as validations for each other. To achieve this, we first converted the data of both modalities to spatialdata-objects and cropped and aligned the H&E image of the Visium HD assay to match the corresponding area of the Xenium HD chip by using the alignment functions of spatialdata.
With the aligned dataset we were able to show that the marker gene for epithelial cells (_CEACAM6_) and a marker gene for crypt base columnar cells (_OLFM4_) are expressed in the same tissue regions.
Finally, we were looking into further methods to analyze these datasets:

- Label transfer from scRNA-seq data to Visium HD (RCTD speed-up verison) and Xenium (SingleR)
- Investigate the impact of different normalization methods on SVG detection, using Visium, Visium HD, and Xenium replicates.
- Merging spatialdata objects of Xenium and Visium HD
- Microenvironment detection using [Banksy](https://github.com/prabhakarlab/Banksy_py) [@singhal_banksy_2022].

### Cellular niches validation metrics

Multiple unsupervised metrics have been added in [this Squidpy PR](https://github.com/scverse/squidpy/pull/831) to evaluate niches detection methods. Notably:

- a niche continuity metric (F1-score of cross-niche edges)
- a cross-slide homogeneity metric (jensen-shannon diverge of niches distributions across slides)
- DE tests to compare max gene expression across niches
- ARI, NMI and Fowlkes-Mallows Index for niche result comparison (agreement)

## Workgroup spatial proteomics

Group members had most experience with analysis of Miltenyi MACSima, Akoya Phenocycler, Lunaphore COMET and MIBI data. After some discussion, four work items were selected.

Some common issues in spatial proteomics analysis were discussed. Reading in datasets in the SpatialData format still lacks for some platforms. Some interesting metadata is also included always included, such as physical pixel size, autofluorescence subtraction, imaging cycles and exposure time. The need in some datasets to detect misalignment and co-register the channel images, either all of them or specific ones. For segmentation, applying CLAHE and using cellpose was found to be sufficient for most cells. For exceptional cell shapes in tissues such as the heart and brain there is additional difficulty and need for fine-tuning the segmentation model with enough training data. This manual labeling is time-consuming and difficult to reproduce. There was a lack of consensus on available normalization techniques, batch effect correction and their usefulness.

### Interoperability with Ilastik and SpatialData

Support for exporting cells in SpatialData and interactively annotating them using a classifier with Ilastik software [@berg_ilastik_2019].

### Overview of normalization methods

Normalization facilitates the integration and comparison of data from different experiments, which is essential for large-scale studies and meta-analyses such as spatial omics data. Therefore, creation of an overview of normalization methods for downstream analysis of spatial proteomics datasets and a comparison between them is crucial.

While evaluation & benchmarking would require a gold standard cell type dataset which is beyond the scope of this hackathon, a [new repository](https://github.com/SchapiroLabor/norm_methods/) was created that contains a summary of 9 methods adapted from published literature. All codes for each method are also available. A visualization of results obtained from these different methods on a MIBI dataset (not publicly available) is provided as well. Among the different methods, a visual qualitative comparison provides evidence that a combined method (Shaban et al. + Greenbaum et al.) may yield more promising results. We plan to extend the work from this hackathon with a quantitative comparison in the future.

### Polygon vectorization

An [alternative](https://github.com/saeyslab/VIB_Hackathon_June_2024/blob/main/polygons/polygons_test.ipynb) to `spatialdata.to_polygons()` label vectorization function, which features improved performance, resolution of the invalid geometries, and `shapely.MultiPolygon` filtering based on the area.

Polygonal representation of cells is crucial for characterizing cellular morphologies and establishing spatial relationships between cells. This method is applicable when cells are located on different planes within tissue, as well as for calculating distances between various objects. However, there is a notable lack of tools that can take a `TIFF` file with cell labels and output a `GeoDataFrame` or `GeoJSON`. The developing branch of the `SpatialData` framework includes a `to_polygons()` vectorization function, but it lacks functionality for resolving invalid geometries and filtering multipolygons.

The following illustrates a practical example: when analyzing thick imaging samples without a _z_-stack, we observe different cell types located in different _z_-planes relative to each other. This is usually not an issue when masks come from mutually exclusive intensity channels. However, with more general markers, we may encounter incorrect and overlapping segmentation masks. Resolving these spatially overlapping segmentation masks through geometrical subtraction often results in fragmented multipolygons with small polygons and lines, affecting downstream applications.

We aim to address the problems of invalid geometries and multipolygon filtering and provide an easy-to-use function compatible with standard `NumPy` arrays (unlike `SpatialData`, which requires a `SpatialImage` instance to perform vectorization). Additionally, our approach improves (~2x increase) performance by avoiding chunking of the input array.

### MACSima spatialdata-io reader

We describe the features of this new reader MACSima datasets in spatialdata-io, with support for lazy loading, physical pixel size and imaging cycles in [this GitHub Issue](https://github.com/scverse/spatialdata-io/issues/155). The draft PR is available [here](https://github.com/scverse/spatialdata-io/pull/156).

## Workgroup spatial multi-omics

Spatial multi-omics are an emerging class of technologies that record two or more data modalities from biological samples in a spatial context. Modalities can among others include RNA, protein, epigenetic features like chromatin accessibility and pathohistological stains. True multi-omic datasets that record multiple modalities of the same cells are rare, which motivates our subproject on **multi-slice alignment** via image registration and integration algorithms.

**Cell morphology**, which is revealed by classical staining methods, is a potential very rich source of information that complements spatial transcriptomic assays like Visium and Xenium. Recently developed vision models allow unsupervised extraction of morphological features which can then be used for clustering and data integration tasks.

### Potential methods for morphology extraction

- [HEIP](https://github.com/ValeAri/HEIP?tab=readme-ov-file)
- [UNI](https://github.com/mahmoodlab/UNI)
- [Resnet50 example](https://github.com/rohanbaisantry/image-clustering)
- [ScDino](https://github.com/JacobHanimann/scDINO) (Immuno fluorescence)

### Spatial transcriptomics + Morphology

- Visium HD Cancer Colon: [Raw data](https://www.10xgenomics.com/datasets/visium-hd-cytassist-gene-expression-libraries-of-human-crc), [Nuclei Segmentation + Domains](https://zenodo.org/records/11402686), [Preprint](https://www.biorxiv.org/content/10.1101/2024.06.04.597233v1)
- Xenium Lung Cancer: [Spatialdata](https://github.com/giovp/spatialdata-sandbox/tree/main/xenium_2.0.0_io), [Raw data](https://www.10xgenomics.com/datasets/preview-data-ffpe-human-lung-cancer-with-xenium-multimodal-cell-segmentation-1-standard)
- Xenium Breast Cancer: [Dataset](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE243168)
- Merfish RNA + IF: [How to dowload](https://colab.research.google.com/drive/1ytuFpC7rCj7TE3foVtrMMutTL8RYqQNj)
- List of Visium, Xenium human cancer datasets: [Notebook](https://spatialdata.scverse.org/en/latest/tutorials/notebooks/datasets/README.html)
- Morphology features via squidpy (tensorflow): [Notebook](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/tutorial_tf.html)

### Alignment of modalities

Multi-modal measurements are usually performed on consecutive slides, which do not align in most cases. In order to perform multi-modal analyses, a correspondence between the measurements is needed. Rigid and affine transforms can help align images between modalities but in real-world cases, the alignment obtained is poor.

We planned on using a [publicly available multi-modal dataset](https://www.nature.com/articles/s41587-023-01937-y) to test different alignment strategies. We tried performing simple affine transformations (e.g., scaling and rotation) but found the alignment to be poor. Other non-affine methods are available in the literature (e.g., [SLAT](https://www.nature.com/articles/s41467-023-43105-5), [ELD](https://www.nature.com/articles/s41592-024-02199-5), [CAST](https://www.biorxiv.org/content/10.1101/2023.08.13.552987v1.full)) but found several issues related to installation and data availability. Despite great promise, the lack of standard multi-modal spatial object representation ultimately hinders the applicability and downstream analyses of aligned datasets.

Another promising avenue is the use of landmarks to perform alignment in a supervised manner. Spatially resolved technologies such as Xenium allow for a single cell resolution unvailable on previous iterations, however, the classic H&E slide is not necessarily outputed as in Visium and Visium HD and is usually done afterward.
It is necessary to align the xenium assay with the H&E slides, this is done through the use of landmarks annotated in both the Xenium and H&E, align and use Napari to visualize the alignment.
The spatialdata package allows for the recovery of the spatial coordinates and the resizing of the H&E slide.

### Collecting datasets and methods

Currently a very limited number of solutions are available for multi-omics integration. Newly developed tools are not widely used, lack proper benchmarking and suffer from a limited number of datasets to perform thorough testing. Here we attempted to collect information on publicly available spatial multi-omics datasets. We also list state-of-the-art computational solutions for horizontal, vertical and diagonal data integration with key details paying special attention to the diagonal unmatched integration. An overview of the collected datasets and methods is provided in [the supplement](https://github.com/saeyslab/VIB_Hackathon_June_2024/blob/main/Multi-omics/supplementary.md).

#### Data integration

Integration challenges:

- number of detected features (e.g. RNA-seq VS proteomics)
- different feature counts, statistical distributions
- differences in resolution (imaging-based)
- image alignment/overlay (imaging-based)
- batch effect
- technical (heavy data)

##### Horizontal

merging the same omic across different datasets
Reasons:

- 3D maps
- technical replicates, integrating batches
- integrating across different technologies

If fact, this is not a true multi-omics integration

Examples:

- [STAGATE](https://doi.org/10.1038/s41467-022-29439-6) (spatial transcriptomics, consecutive sections, adaptive graph attention auto-encoder)
- [STAligner](https://doi.org/10.1038/s43588-023-00543-x) (spatial transcriptomics datasets, batch effect-corrected embeddings, 3D reconstruction, )
- [SpaGCN](https://doi.org/10.1038/s41592-021-01255-8) (spatial transcriptomics, graph convolutional network approach that integrates gene expression, spatial location and histology)
- [PASTE](https://www.nature.com/articles/s41592-022-01459-6) (align and integrate ST data from multiple adjacent tissue sections)
- [SpaceFlow](https://doi.org/10.1038/s41467-022-31739-w) (embedding is continuous both in space and time, Deep Graph Infomax (DGI) framework with spatial regularization)

##### Vertical

Merges data from different omics within the same set of samples (matched integration), using cell as an anchor.
Examples:

- [archr](https://doi.org/10.1038/s41588-021-00790-6)
- [MaxFuse](https://doi.org/10.1038/s41587-023-01935-0) (fuzzy smoothed embedding for weaky-linked modalities, proteomics, transcriptomics and epigenomics at single-cell resolution on the same tissue section)
- [MultiMAP](https://doi.org/10.1186/s13059-021-02565-y) (nonlinear manifold learning algorithm that recovers a single manifold on which several datasets reside and then projects the data into a single low-dimensional space so as to preserve the manifold structure)
- Seurat5

##### Diagonal

Some examples of studies with unmatched integration:

- [SpatialGlue](https://doi.org/10.1101/2023.04.26.538404)
  - graph neural network with dual-attention mechanism
  - 2 separate graphs to encode data into common embedding space: a spatial proximity graph and a feature graph
- [MEFISTO](https://doi.org/10.1038/s41592-021-01343-9)
  - factor analysis + flexible non-parametric framework of Gaussian processes
  - spatio-temporally informed dimensionality reduction, interpolation, and separation of smooth from non-smooth patterns of variation.
  - different omics, multiple sets of samples (different experimental conditions, species or individuals)
  - each sample is characterized by "view", "group", and by a continuous covariate such as a one-dimensional temporal or two-dimensional spatial coordinate
- [SLAT](https://doi.org/10.1038/s41467-023-43105-5)
  - aligning heterogenous spatial data across distinct technologies and modalities
  - graph adversarial matching
- [Cross-modality mapping using image varifolds](https://doi.org/10.1038/s41467-024-47883-4)

Additional details on this methods are summarized in [supplementary Table 1](https://github.com/saeyslab/VIB_Hackathon_June_2024/blob/main/Multi-omics/supplementary.md).
General issue: gene-based, challenges with proteomics (and even more issues with metabolomics).
Direct comparison of these tools is not possible due to different tasks and working principles.

### _In silico_ datasets generation

Due to the limited number of available spatial datasets and their complexity, the tools for _in silico_ generation of artificial spatial datasets are becoming more popular. Such tools may be useful for experimental design planning, selecting sampling strategy to get reliable statistics, and for benchmarking of new tools. Unfortunately, some of the current solutions cause serious technical issues during installation and running. Here we list 3 existing tools for dataset generation:

- [Power analysis for spatial omics](https://www.nature.com/articles/s41592-023-01766-6)
  - tissue scaffold: random-circle-packing algorithm to generate a planar graph
  - attributes on nodes represent cell type assignments
  - the labeling is based on two data-driven parameters (prior knowledge) for a tissue type: the proportions of the k unique cell types, and the pairwise probabilities of each possible cell type pair being adjacent (a k × k matrix)
  - by changing these 2 params one should be able to obtain simulations for different tissues and technologies
  - we faced some technical issues while using this tool
- [scDesign3](https://www.nature.com/articles/s41587-023-01772-1)
- [SRTsim](https://doi.org/10.1186/s13059-023-02879-z) (transcriptomics only)

### Image Registration

Spatial landmark detection and tissue registration with deep learning: [paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11009106/) and [code](https://github.com/ekvall93/ELD).

### Morphological Feature Extraction

Multiple vision models were evaluated for feature extraction from Hematoxylin and eosin stains. This includes general purpose vision models included in torchvision like Resnet50 and Inceptionv3 and also a dedicated pathology model in UNI. Our results show that multiple models successfully extract region specific features from the images. UNI in particular performed strongly with an ARI XXX of compared to pathologist annotation. It remains to be seen how these features can best be integrated with RNA information for clustering and spatial domain identification.

## Workgroup cell-cell communication

The goal of the group was to run multiple spatial CCC methods and compare evaluations/visualizations and results. We selected the methods from [@armingol_diversification_2024](https://pubmed.ncbi.nlm.nih.gov/38238518/). A more detailed table can be found on the [separate GitHub repository of this workgroup](https://github.com/saeyslab/spatial_ccc_experiments).

### Results

Methods were implemented and tested on a subset of the MERFISH whole mouse brain data (slice 80) from the [Allen Brain Institute](https://knowledge.brain-map.org/data/5C0201JSVE04WY6DMVC/collections).

We obtained results for CCC for the following methods: [COMMOT](https://www.nature.com/articles/s41592-022-01728-4), [SpatialDM](https://www.nature.com/articles/s41467-023-39608-w), [MEBOCOST](https://www.biorxiv.org/content/10.1101/2022.05.30.494067v1), [CellPhoneDB](https://www.nature.com/articles/s41596-020-0292-x). SpatialDM and CellPhoneDB were run with [LIANA+](https://www.biorxiv.org/content/10.1101/2023.08.19.553863v1). We also ran SpaTalk but found no LR pairs, as the tool requires that the entire ligand-receptor-tf-target pathway is expressed for a LR pair to be considered, and this was likely not the case in a dataset with 1122 genes. For the other three tools we selected specific LR pairs to compare the results.

#### Comparison on cell type level

Do the tools identify the same sender and receiver cells that participate at communication?

LIANA+ (CellPhoneDB) and COMMOT find common ligand-receptor pairs, however, among the few cell-type source-target pairs we investigated, there was no consensus.
The comparison was performed on a qualitative way rather than quantitative due to difference in output format and evaluation metrics used by the different tools.
Because MEBOCOST does not use Ligand-Receptor interactions as the other tools but it calculates metabolic communication scores, we could not compare the results directly.

#### Comparison on spatial level

Where do the tools predict the communication to take place in tissue space? Do spatial methods benefit from the additional modality?

COMMOT and SpatialDM both make use of spatial information to predict the communication events. We investigated the LR pair Nts-Ntsr2; the cells seem to interact in the same brain region (hypothalamus).

### Discussion

- Comparison of results is difficult because i) there is no ground thruth regarding CCC, ii) output formats of methods vary, for example SpatialDM returns a $NxLR$ matrix with a score for each cell indicating the potential strength of a ligand or receptor and COMMOT returns a $NxN$ matrix for each $LR$ interaction, iii) different score metric.
- A more systematic comparison should be carried out over all cell types and all ligand-receptor pairs.
- Different input databases on which communication analysis is based (metabolic vs ligand-receptor) but also within LR interactions it might use the CellPhoneDB or CellChat database.

# Conclusions

This hackathon was attended by 37 participants from many institutes across Europe. It provided a useful venue for the exchange of ideas and the development of new tools and methods for spatial omics data analysis. Status updates and results were summarized in a [slide deck](https://drive.google.com/drive/folders/1UCgpO5GtsGs4e7jMMgy-DCtLMThnfH_m). A [project board](https://github.com/orgs/saeyslab/projects/5) collected all task items and a [Zulip stream](https://imagesc.zulipchat.com/#narrow/stream/421189-Zzz.3A-.5B2024-06.5D-VIB-Hackathon-Ghent.3A-spatial-omics) was used for communication. Code to use the provided computational resources and some of the hackathon results are available in [this code repository](https://github.com/saeyslab/VIB_Hackathon_June_2024).

# Acknowledgements

The hackathon was organized by the Saeys Lab and supported by Data Intuitive, the VIB Spatial Catalyst and the VIB Center for AI and Computational Biology.

The computational resources and services used in this work were provided by the VIB Data Core and the VSC (Flemish Super-computer Center), funded by the Research Foundation – Flanders (FWO) and the Flemish Government. B.R, R.S. and Y.S. are supported by the Flanders AI Research Program.

# References
